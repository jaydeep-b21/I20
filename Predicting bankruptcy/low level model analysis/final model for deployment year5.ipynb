{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data=pd.read_csv(r\"C:\\Users\\CG-DTE\\Desktop\\AI\\GITHUB\\Predicting bankruptcy\\low level model analysis\\5year.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### above feature set i have gone through some feature engineering steps\n",
    "#### missing imputation------>gaussian transformation ----->decision tree descritisation------>scaling --->feature selection\n",
    "#### [['Attr1', 'Attr4', 'Attr21', 'Attr27', 'Attr34', 'Attr35', 'Attr52', 'Attr53', 'Attr58']] i got these features\n",
    "\n",
    "### but important analysis i found that feature set using these above feature engineering steps giving best result on original data aftter imputation only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_4=data[['Attr1', 'Attr4', 'Attr21', 'Attr27', 'Attr34', 'Attr35', 'Attr52', 'Attr53', 'Attr58','class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1=year_4.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-763fa34d3bd1>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  year_4[i] = year_4[i].replace('?' , np.nan)\n"
     ]
    }
   ],
   "source": [
    "#replacing each ? to NAN\n",
    "for i in k1:\n",
    "    year_4[i] = year_4[i].replace('?' , np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting object data into numericals(float64)\n",
    "year_4=year_4.apply(lambda col:pd.to_numeric(col,errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attr1</th>\n",
       "      <th>Attr4</th>\n",
       "      <th>Attr21</th>\n",
       "      <th>Attr27</th>\n",
       "      <th>Attr34</th>\n",
       "      <th>Attr35</th>\n",
       "      <th>Attr52</th>\n",
       "      <th>Attr53</th>\n",
       "      <th>Attr58</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088238</td>\n",
       "      <td>1.02050</td>\n",
       "      <td>1.15740</td>\n",
       "      <td>1.03870</td>\n",
       "      <td>0.24377</td>\n",
       "      <td>0.135230</td>\n",
       "      <td>0.42557</td>\n",
       "      <td>0.73717</td>\n",
       "      <td>0.91905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.006202</td>\n",
       "      <td>1.59980</td>\n",
       "      <td>1.01580</td>\n",
       "      <td>0.17118</td>\n",
       "      <td>2.70750</td>\n",
       "      <td>-0.036475</td>\n",
       "      <td>0.29604</td>\n",
       "      <td>1.36140</td>\n",
       "      <td>1.00470</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.130240</td>\n",
       "      <td>3.60820</td>\n",
       "      <td>1.23620</td>\n",
       "      <td>1.47370</td>\n",
       "      <td>0.65878</td>\n",
       "      <td>0.145860</td>\n",
       "      <td>0.22371</td>\n",
       "      <td>3.36840</td>\n",
       "      <td>0.87604</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089951</td>\n",
       "      <td>1.52220</td>\n",
       "      <td>1.09420</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.83567</td>\n",
       "      <td>0.014027</td>\n",
       "      <td>0.69565</td>\n",
       "      <td>0.52538</td>\n",
       "      <td>0.59074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.048179</td>\n",
       "      <td>1.24370</td>\n",
       "      <td>0.99455</td>\n",
       "      <td>2.06710</td>\n",
       "      <td>2.13360</td>\n",
       "      <td>0.364200</td>\n",
       "      <td>0.37618</td>\n",
       "      <td>0.99779</td>\n",
       "      <td>0.77048</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5905</th>\n",
       "      <td>0.012898</td>\n",
       "      <td>1.17220</td>\n",
       "      <td>1.03300</td>\n",
       "      <td>1.46370</td>\n",
       "      <td>2.36440</td>\n",
       "      <td>0.033819</td>\n",
       "      <td>0.13514</td>\n",
       "      <td>0.39944</td>\n",
       "      <td>1.01220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5906</th>\n",
       "      <td>-0.578050</td>\n",
       "      <td>0.16576</td>\n",
       "      <td>0.64770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.55316</td>\n",
       "      <td>-0.534920</td>\n",
       "      <td>0.20912</td>\n",
       "      <td>-0.46385</td>\n",
       "      <td>1.06410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5907</th>\n",
       "      <td>-0.179050</td>\n",
       "      <td>0.74554</td>\n",
       "      <td>0.83104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.14077</td>\n",
       "      <td>0.176700</td>\n",
       "      <td>0.66913</td>\n",
       "      <td>-1.70670</td>\n",
       "      <td>0.85112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5908</th>\n",
       "      <td>-0.108860</td>\n",
       "      <td>1.08780</td>\n",
       "      <td>1.12100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.13435</td>\n",
       "      <td>-0.099950</td>\n",
       "      <td>0.19247</td>\n",
       "      <td>0.11530</td>\n",
       "      <td>1.18320</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5909</th>\n",
       "      <td>-0.105370</td>\n",
       "      <td>0.91478</td>\n",
       "      <td>0.71351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.15467</td>\n",
       "      <td>-0.082947</td>\n",
       "      <td>0.35632</td>\n",
       "      <td>0.90779</td>\n",
       "      <td>1.05220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5910 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Attr1    Attr4   Attr21   Attr27   Attr34    Attr35   Attr52  \\\n",
       "0     0.088238  1.02050  1.15740  1.03870  0.24377  0.135230  0.42557   \n",
       "1    -0.006202  1.59980  1.01580  0.17118  2.70750 -0.036475  0.29604   \n",
       "2     0.130240  3.60820  1.23620  1.47370  0.65878  0.145860  0.22371   \n",
       "3    -0.089951  1.52220  1.09420  0.00000  0.83567  0.014027  0.69565   \n",
       "4     0.048179  1.24370  0.99455  2.06710  2.13360  0.364200  0.37618   \n",
       "...        ...      ...      ...      ...      ...       ...      ...   \n",
       "5905  0.012898  1.17220  1.03300  1.46370  2.36440  0.033819  0.13514   \n",
       "5906 -0.578050  0.16576  0.64770      NaN -0.55316 -0.534920  0.20912   \n",
       "5907 -0.179050  0.74554  0.83104      NaN  0.14077  0.176700  0.66913   \n",
       "5908 -0.108860  1.08780  1.12100      NaN -0.13435 -0.099950  0.19247   \n",
       "5909 -0.105370  0.91478  0.71351      NaN -0.15467 -0.082947  0.35632   \n",
       "\n",
       "       Attr53   Attr58  class  \n",
       "0     0.73717  0.91905      0  \n",
       "1     1.36140  1.00470      0  \n",
       "2     3.36840  0.87604      0  \n",
       "3     0.52538  0.59074      0  \n",
       "4     0.99779  0.77048      0  \n",
       "...       ...      ...    ...  \n",
       "5905  0.39944  1.01220      1  \n",
       "5906 -0.46385  1.06410      1  \n",
       "5907 -1.70670  0.85112      1  \n",
       "5908  0.11530  1.18320      1  \n",
       "5909  0.90779  1.05220      1  \n",
       "\n",
       "[5910 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### so here i m building model on entire dataset for , so i m not divinding into train and test dataset , so that i do have ample amount of data to train our model more accurately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors=['Attr1', 'Attr4', 'Attr21', 'Attr27', 'Attr34', 'Attr35', 'Attr52', 'Attr53', 'Attr58']\n",
    "target=['class']\n",
    "X=year_4[predictors]\n",
    "y=year_4[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X\n",
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we impute the missing values with SimpleImputer\n",
    "\n",
    "# create an instance of the simple imputer\n",
    "# we indicate that we want to impute with the median\n",
    "mean_imputer = SimpleImputer(strategy='mean',)\n",
    "\n",
    "# we fit and transform the predictors dataframe\n",
    "# the imputer will learn the mean of all variables\n",
    "X_new=mean_imputer.fit_transform(X[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1=y.copy()\n",
    "X_1=pd.DataFrame(X_new, columns=predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### over sampling through SMOTE is performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 2) \n",
    "X_res, y_res = sm.fit_resample(X_1, y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(y_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:- since , i have not splited my data into train-test dataset so my independent and dependent data are in pandas dataframe so in order to implement in XGBoostingClassifier algo in pickled , model will not take dataframe data as input to predict , so i need to convert X(input data ) into numpy array , i m not converting y into numpy array¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(X_res)\n",
    "type(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(X_res)\n",
    "y=np.array(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(X)\n",
    "#type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "# Classification metrices\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix, classification_report, precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functionalizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functionalize model fittting\n",
    "\n",
    "def FitModel(X,Y,algo_name,algorithm,gridSearchParams,cv):\n",
    "    np.random.seed(10)\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,Y, test_size = 0.2)\n",
    "    \n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator=algorithm,\n",
    "        param_grid=gridSearchParams,\n",
    "        cv=cv, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "    \n",
    "    \n",
    "    grid_result = grid.fit(x_train, y_train)\n",
    "    best_params = grid_result.best_params_\n",
    "    pred = grid_result.predict(x_test)\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "   # metrics =grid_result.gr\n",
    "    print(pred)\n",
    "    pickle.dump(grid_result,open(algo_name,'wb'))\n",
    "   \n",
    "    print('Best Params :',best_params)\n",
    "    print('Classification Report :',classification_report(y_test,pred))\n",
    "    print('Accuracy Score : ' + str(accuracy_score(y_test,pred)))\n",
    "    print('Confusion Matrix : \\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CG-DTE\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\CG-DTE\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\CG-DTE\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:58:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0 1 1 ... 0 1 0]\n",
      "Best Params : {'n_estimators': 500}\n",
      "Classification Report :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1139\n",
      "           1       0.95      0.98      0.97      1061\n",
      "\n",
      "    accuracy                           0.97      2200\n",
      "   macro avg       0.97      0.97      0.97      2200\n",
      "weighted avg       0.97      0.97      0.97      2200\n",
      "\n",
      "Accuracy Score : 0.9663636363636363\n",
      "Confusion Matrix : \n",
      " [[1086   53]\n",
      " [  21 1040]]\n"
     ]
    }
   ],
   "source": [
    "param ={\n",
    "            'n_estimators': [50, 100, 500, 1000, 2000],\n",
    "           \n",
    "        }\n",
    "FitModel(X,y,'finalized_model1.pkl',XGBClassifier(),param,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reloading the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"finalized_model1.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = loaded_model.predict(np.array([[0.035999,1.55860,1.32360,0.88616,0.24767,0.084147,0.297850,1.07620,0.90850]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change (prediction):\n",
    "    if prediction==1:\n",
    "        return 'yes'\n",
    "    else:\n",
    "        return 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some of the features of company:-\n",
      "net profit / total assets = 0.035999\n",
      "current assets / short-term liabilities = 1.55860 \n",
      "sales (n) / sales (n-1) = 1.32360\n",
      "profit on operating activities / financial expenses = 0.88616\n",
      "operating expenses / total liabilities = 0.24767\n",
      "profit on sales / total assets = 0.084147\n",
      "(short-term liabilities * 365) / cost of products sold) = 0.297850\n",
      "equity / fixed assets = 1.07620\n",
      "total costs /total sales = 0.90850\n",
      "\n",
      "\n",
      "\n",
      "will company go for bankruptcy ? No\n"
     ]
    }
   ],
   "source": [
    "print('some of the features of company:-')\n",
    "print('net profit / total assets = 0.035999')\n",
    "print('current assets / short-term liabilities = 1.55860 ')\n",
    "print('sales (n) / sales (n-1) = 1.32360')\n",
    "print('profit on operating activities / financial expenses = 0.88616')\n",
    "print('operating expenses / total liabilities = 0.24767')\n",
    "print('profit on sales / total assets = 0.084147')\n",
    "print('(short-term liabilities * 365) / cost of products sold) = 0.297850')\n",
    "print('equity / fixed assets = 1.07620')\n",
    "print('total costs /total sales = 0.90850')\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "print('will company go for bankruptcy ? {}'.format(change(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
